{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPNrenAjE/JJyzaJoTIQvFW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aaronfarquhar/13006610-dataanylitics/blob/main/Assessment_2_DAOTW_part2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "PAQBTUgSDhVO"
      },
      "outputs": [],
      "source": [
        "#imports for python\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "#read data source and create dataframe\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/aaronfarquhar/13006610-dataanylitics/main/Collated_Data_Assessment_2_13006610.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.__version__) #for checking the tensorflow import"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkz97mANL8Np",
        "outputId": "2aec37ba-2f98-4afd-dd07-8924725e9e70"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check data is present and succsessfully read\n",
        "print(df)"
      ],
      "metadata": {
        "id": "Sxqme4JGEJM5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "deb2e2bf-6155-4fc1-dcd8-563d8b1276b0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      temp  visib  day  mo  year  NUM_COLLISIONS\n",
            "0     76.0    8.9    1   7  2012             505\n",
            "1     78.5   10.0    1   7  2012             533\n",
            "2     79.0    9.2    1   7  2012             528\n",
            "3     73.1   10.0    1   7  2012             530\n",
            "4     80.3   10.0    1   7  2012             564\n",
            "...    ...    ...  ...  ..   ...             ...\n",
            "3160  51.5    6.3    6  12  2020             278\n",
            "3161  38.5   10.0    7  12  2020             194\n",
            "3162  39.3    9.8    7  12  2020             241\n",
            "3163  53.4    6.3    7  12  2020             265\n",
            "3164  34.2   10.0    7  12  2020             184\n",
            "\n",
            "[3165 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "the collated data will be the same as before"
      ],
      "metadata": {
        "id": "cbbdxujfHXpc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#temp and collisions table\n",
        "inputs_for_training = [df['visib'], df['NUM_COLLISIONS']]\n",
        "header = ['Visibility', 'Number of Collisions']\n",
        "combined1 = pd.concat(inputs_for_training, axis = 1, keys=header)\n",
        "print (combined1)"
      ],
      "metadata": {
        "id": "tY07BP6FFX2H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e1d683c-97e4-41af-edbc-dd92131a1bb2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Visibility  Number of Collisions\n",
            "0            8.9                   505\n",
            "1           10.0                   533\n",
            "2            9.2                   528\n",
            "3           10.0                   530\n",
            "4           10.0                   564\n",
            "...          ...                   ...\n",
            "3160         6.3                   278\n",
            "3161        10.0                   194\n",
            "3162         9.8                   241\n",
            "3163         6.3                   265\n",
            "3164        10.0                   184\n",
            "\n",
            "[3165 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#training and testing data\n",
        "train_dataset = combined1.sample(frac=0.8, random_state=0)\n",
        "test_dataset = combined1.drop(train_dataset.index)\n",
        "\n",
        "#prints for checking\n",
        "print(train_dataset)\n",
        "print(test_dataset)\n"
      ],
      "metadata": {
        "id": "S4PEpIebWnZ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69d883de-625e-4d3e-a271-04c633cb773e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Visibility  Number of Collisions\n",
            "2533         6.3                   592\n",
            "1436         6.4                   638\n",
            "2567        10.0                   722\n",
            "3139         9.3                   320\n",
            "1473         9.7                   742\n",
            "...          ...                   ...\n",
            "1181         6.9                   545\n",
            "337          2.0                   707\n",
            "46          10.0                   618\n",
            "747          9.8                   451\n",
            "2891         9.9                   127\n",
            "\n",
            "[2532 rows x 2 columns]\n",
            "      Visibility  Number of Collisions\n",
            "0            8.9                   505\n",
            "3           10.0                   530\n",
            "7            8.1                   574\n",
            "21          10.0                   638\n",
            "24           9.5                   490\n",
            "...          ...                   ...\n",
            "3142        10.0                   315\n",
            "3143        10.0                   238\n",
            "3145        10.0                   360\n",
            "3153        10.0                   348\n",
            "3159         8.6                   285\n",
            "\n",
            "[633 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_copy = train_dataset.copy()\n",
        "test_copy = test_dataset.copy()\n",
        "\n",
        "training_label = train_copy.pop('Number of Collisions')\n",
        "testing_labels = test_copy.pop('Number of Collisions')\n",
        "\n",
        "print(test_copy)\n",
        "print(testing_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNhuRlR4YZrk",
        "outputId": "66c85222-9a5f-4fa1-cae2-c8609b7a4e91"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Visibility\n",
            "0            8.9\n",
            "3           10.0\n",
            "7            8.1\n",
            "21          10.0\n",
            "24           9.5\n",
            "...          ...\n",
            "3142        10.0\n",
            "3143        10.0\n",
            "3145        10.0\n",
            "3153        10.0\n",
            "3159         8.6\n",
            "\n",
            "[633 rows x 1 columns]\n",
            "0       505\n",
            "3       530\n",
            "7       574\n",
            "21      638\n",
            "24      490\n",
            "       ... \n",
            "3142    315\n",
            "3143    238\n",
            "3145    360\n",
            "3153    348\n",
            "3159    285\n",
            "Name: Number of Collisions, Length: 633, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers.preprocessing import normalization\n",
        "normalisation_layer = tf.keras.layers.Normalization(input_shape=[1,], axis = None)\n",
        "#convert values to -1 to 1\n",
        "normalisation_layer.adapt(np.array(train_copy))"
      ],
      "metadata": {
        "id": "FA5h5Hkcetdm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The sateps above are the same as for the linear regresion model in part one and do not need elaberation. how ever below a number of extra layers are created between the normalisation layer and the output layer. theses extra, dense layers start at 256 nodes and half the number of nodes at each layer. this should hopefully increase the accuracy of the model though a Deep Neural Networks value in so simple a case is dubious."
      ],
      "metadata": {
        "id": "Vv6GFnIYHnDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=tf.keras.Sequential([\n",
        "    normalisation_layer,\n",
        "    tf.keras.layers.Dense(256, activation=tf.keras.activations.relu),\n",
        "    tf.keras.layers.Dense(128, activation=tf.keras.activations.relu),\n",
        "    tf.keras.layers.Dense(64, activation=tf.keras.activations.relu),\n",
        "    tf.keras.layers.Dense(32, activation=tf.keras.activations.relu),\n",
        "    tf.keras.layers.Dense(16, activation=tf.keras.activations.relu),\n",
        "    tf.keras.layers.Dense(8, activation=tf.keras.activations.relu),\n",
        "    tf.keras.layers.Dense(4, activation=tf.keras.activations.relu),\n",
        "    tf.keras.layers.Dense(2, activation=tf.keras.activations.relu),\n",
        "    tf.keras.layers.Dense(units=1)\n",
        "])"
      ],
      "metadata": {
        "id": "XzPU0YRBiRgy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer = tf.optimizers.Adam(learning_rate = 0.1),\n",
        "    loss = 'mean_absolute_error'\n",
        "    )"
      ],
      "metadata": {
        "id": "TZejcxJP2Aqh"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "model_output = model.fit(train_copy, training_label, epochs=100, validation_split = 0.2, verbose = 1 )"
      ],
      "metadata": {
        "id": "rbtb5Ore3BdQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68f1ea8d-c26b-4260-970e-06a6a95cf485"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "64/64 [==============================] - 3s 9ms/step - loss: 558.0606 - val_loss: 554.5764\n",
            "Epoch 2/100\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 551.6591 - val_loss: 548.1765\n",
            "Epoch 3/100\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 545.2592 - val_loss: 541.7766\n",
            "Epoch 4/100\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 538.8592 - val_loss: 535.3766\n",
            "Epoch 5/100\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 532.4594 - val_loss: 528.9767\n",
            "Epoch 6/100\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 526.0594 - val_loss: 522.5768\n",
            "Epoch 7/100\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 519.6595 - val_loss: 516.1769\n",
            "Epoch 8/100\n",
            "64/64 [==============================] - 0s 5ms/step - loss: 513.2598 - val_loss: 509.7771\n",
            "Epoch 9/100\n",
            "64/64 [==============================] - 0s 5ms/step - loss: 506.8598 - val_loss: 503.3772\n",
            "Epoch 10/100\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 500.4599 - val_loss: 496.9773\n",
            "Epoch 11/100\n",
            "64/64 [==============================] - 0s 5ms/step - loss: 494.0599 - val_loss: 490.5774\n",
            "Epoch 12/100\n",
            "64/64 [==============================] - 0s 5ms/step - loss: 487.6601 - val_loss: 484.1775\n",
            "Epoch 13/100\n",
            "64/64 [==============================] - 0s 5ms/step - loss: 481.2603 - val_loss: 477.7776\n",
            "Epoch 14/100\n",
            "64/64 [==============================] - 0s 4ms/step - loss: 474.8603 - val_loss: 471.3777\n",
            "Epoch 15/100\n",
            "64/64 [==============================] - 0s 5ms/step - loss: 468.4615 - val_loss: 464.9818\n",
            "Epoch 16/100\n",
            "64/64 [==============================] - 0s 5ms/step - loss: 462.0730 - val_loss: 458.5890\n",
            "Epoch 17/100\n",
            "64/64 [==============================] - 0s 5ms/step - loss: 455.6947 - val_loss: 452.2050\n",
            "Epoch 18/100\n",
            "64/64 [==============================] - 0s 4ms/step - loss: 449.3375 - val_loss: 445.8174\n",
            "Epoch 19/100\n",
            "64/64 [==============================] - 0s 5ms/step - loss: 442.9991 - val_loss: 439.4622\n",
            "Epoch 20/100\n",
            "64/64 [==============================] - 0s 4ms/step - loss: 436.6620 - val_loss: 433.0955\n",
            "Epoch 21/100\n",
            "64/64 [==============================] - 0s 5ms/step - loss: 430.3428 - val_loss: 426.7588\n",
            "Epoch 22/100\n",
            "64/64 [==============================] - 0s 5ms/step - loss: 424.0461 - val_loss: 420.4461\n",
            "Epoch 23/100\n",
            "64/64 [==============================] - 0s 4ms/step - loss: 417.7850 - val_loss: 414.1928\n",
            "Epoch 24/100\n",
            "64/64 [==============================] - 0s 5ms/step - loss: 411.5530 - val_loss: 407.9462\n",
            "Epoch 25/100\n",
            "64/64 [==============================] - 0s 4ms/step - loss: 405.3365 - val_loss: 401.7370\n",
            "Epoch 26/100\n",
            "64/64 [==============================] - 0s 4ms/step - loss: 399.1373 - val_loss: 395.5373\n",
            "Epoch 27/100\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 392.9582 - val_loss: 389.4016\n",
            "Epoch 28/100\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 386.8207 - val_loss: 383.2968\n",
            "Epoch 29/100\n",
            "64/64 [==============================] - 0s 4ms/step - loss: 380.7136 - val_loss: 377.2600\n",
            "Epoch 30/100\n",
            "64/64 [==============================] - 0s 4ms/step - loss: 374.6338 - val_loss: 371.2494\n",
            "Epoch 31/100\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 368.5891 - val_loss: 365.2939\n",
            "Epoch 32/100\n",
            "64/64 [==============================] - 0s 4ms/step - loss: 362.6020 - val_loss: 359.3225\n",
            "Epoch 33/100\n",
            "64/64 [==============================] - 0s 4ms/step - loss: 356.6222 - val_loss: 353.3764\n",
            "Epoch 34/100\n",
            "64/64 [==============================] - 0s 4ms/step - loss: 350.6643 - val_loss: 347.3962\n",
            "Epoch 35/100\n",
            "64/64 [==============================] - 0s 4ms/step - loss: 344.7026 - val_loss: 341.4395\n",
            "Epoch 36/100\n",
            "64/64 [==============================] - 0s 5ms/step - loss: 338.7685 - val_loss: 335.5607\n",
            "Epoch 37/100\n",
            "64/64 [==============================] - 0s 4ms/step - loss: 332.8752 - val_loss: 329.6706\n",
            "Epoch 38/100\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 326.9975 - val_loss: 323.7966\n",
            "Epoch 39/100\n",
            "64/64 [==============================] - 0s 4ms/step - loss: 321.1807 - val_loss: 317.9898\n",
            "Epoch 40/100\n",
            "64/64 [==============================] - 0s 4ms/step - loss: 315.4257 - val_loss: 312.2258\n",
            "Epoch 41/100\n",
            "64/64 [==============================] - 0s 4ms/step - loss: 309.7323 - val_loss: 306.5752\n",
            "Epoch 42/100\n",
            "64/64 [==============================] - 0s 5ms/step - loss: 304.0792 - val_loss: 300.9531\n",
            "Epoch 43/100\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 298.4519 - val_loss: 295.4037\n",
            "Epoch 44/100\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 292.8439 - val_loss: 289.8547\n",
            "Epoch 45/100\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 287.3115 - val_loss: 284.3765\n",
            "Epoch 46/100\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 281.8728 - val_loss: 278.9876\n",
            "Epoch 47/100\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 276.5225 - val_loss: 273.6555\n",
            "Epoch 48/100\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 271.2384 - val_loss: 268.4041\n",
            "Epoch 49/100\n",
            "64/64 [==============================] - 0s 4ms/step - loss: 266.0303 - val_loss: 263.2243\n",
            "Epoch 50/100\n",
            "64/64 [==============================] - 0s 4ms/step - loss: 260.9445 - val_loss: 258.1579\n",
            "Epoch 51/100\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 255.9606 - val_loss: 253.1675\n",
            "Epoch 52/100\n",
            "64/64 [==============================] - 0s 4ms/step - loss: 251.0640 - val_loss: 248.2154\n",
            "Epoch 53/100\n",
            "64/64 [==============================] - 0s 4ms/step - loss: 246.2639 - val_loss: 243.3047\n",
            "Epoch 54/100\n",
            "64/64 [==============================] - 0s 4ms/step - loss: 241.5012 - val_loss: 238.4867\n",
            "Epoch 55/100\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 236.8109 - val_loss: 233.7178\n",
            "Epoch 56/100\n",
            "64/64 [==============================] - 0s 4ms/step - loss: 232.1809 - val_loss: 229.0029\n",
            "Epoch 57/100\n",
            "64/64 [==============================] - 0s 4ms/step - loss: 227.6051 - val_loss: 224.3196\n",
            "Epoch 58/100\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 223.0494 - val_loss: 219.6329\n",
            "Epoch 59/100\n",
            "64/64 [==============================] - 0s 4ms/step - loss: 218.5301 - val_loss: 214.9848\n",
            "Epoch 60/100\n",
            "64/64 [==============================] - 0s 4ms/step - loss: 214.0249 - val_loss: 210.3301\n",
            "Epoch 61/100\n",
            "64/64 [==============================] - 0s 4ms/step - loss: 209.5117 - val_loss: 205.6603\n",
            "Epoch 62/100\n",
            "64/64 [==============================] - 0s 4ms/step - loss: 205.0601 - val_loss: 201.0910\n",
            "Epoch 63/100\n",
            "64/64 [==============================] - 0s 4ms/step - loss: 200.6576 - val_loss: 196.5146\n",
            "Epoch 64/100\n",
            "64/64 [==============================] - 0s 5ms/step - loss: 196.2704 - val_loss: 191.9614\n",
            "Epoch 65/100\n",
            "64/64 [==============================] - 0s 5ms/step - loss: 191.9443 - val_loss: 187.5200\n",
            "Epoch 66/100\n",
            "64/64 [==============================] - 0s 4ms/step - loss: 187.6817 - val_loss: 183.0698\n",
            "Epoch 67/100\n",
            "64/64 [==============================] - 0s 4ms/step - loss: 183.4797 - val_loss: 178.6931\n",
            "Epoch 68/100\n",
            "64/64 [==============================] - 0s 5ms/step - loss: 179.3341 - val_loss: 174.5700\n",
            "Epoch 69/100\n",
            "64/64 [==============================] - 0s 4ms/step - loss: 175.2512 - val_loss: 170.4105\n",
            "Epoch 70/100\n",
            "64/64 [==============================] - 0s 5ms/step - loss: 171.2123 - val_loss: 166.2960\n",
            "Epoch 71/100\n",
            "64/64 [==============================] - 0s 5ms/step - loss: 167.2225 - val_loss: 162.3191\n",
            "Epoch 72/100\n",
            "64/64 [==============================] - 0s 5ms/step - loss: 163.3357 - val_loss: 158.3863\n",
            "Epoch 73/100\n",
            "64/64 [==============================] - 0s 4ms/step - loss: 159.5486 - val_loss: 154.6427\n",
            "Epoch 74/100\n",
            "64/64 [==============================] - 0s 5ms/step - loss: 155.8800 - val_loss: 150.9599\n",
            "Epoch 75/100\n",
            "64/64 [==============================] - 0s 4ms/step - loss: 152.3189 - val_loss: 147.4514\n",
            "Epoch 76/100\n",
            "64/64 [==============================] - 0s 4ms/step - loss: 148.9378 - val_loss: 144.1097\n",
            "Epoch 77/100\n",
            "64/64 [==============================] - 0s 5ms/step - loss: 145.7001 - val_loss: 140.8312\n",
            "Epoch 78/100\n",
            "64/64 [==============================] - 0s 4ms/step - loss: 142.5656 - val_loss: 137.6564\n",
            "Epoch 79/100\n",
            "64/64 [==============================] - 0s 4ms/step - loss: 139.5578 - val_loss: 134.6559\n",
            "Epoch 80/100\n",
            "64/64 [==============================] - 0s 5ms/step - loss: 136.6864 - val_loss: 131.8535\n",
            "Epoch 81/100\n",
            "64/64 [==============================] - 0s 5ms/step - loss: 134.0047 - val_loss: 129.2336\n",
            "Epoch 82/100\n",
            "64/64 [==============================] - 0s 5ms/step - loss: 131.4819 - val_loss: 126.7037\n",
            "Epoch 83/100\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 129.0348 - val_loss: 124.2827\n",
            "Epoch 84/100\n",
            "64/64 [==============================] - 0s 4ms/step - loss: 126.7080 - val_loss: 122.0749\n",
            "Epoch 85/100\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 124.5128 - val_loss: 120.0141\n",
            "Epoch 86/100\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 122.4411 - val_loss: 118.0479\n",
            "Epoch 87/100\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 120.4786 - val_loss: 116.2870\n",
            "Epoch 88/100\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 118.6246 - val_loss: 114.7116\n",
            "Epoch 89/100\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 116.9612 - val_loss: 113.3438\n",
            "Epoch 90/100\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 115.4765 - val_loss: 112.1699\n",
            "Epoch 91/100\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 114.1342 - val_loss: 111.0660\n",
            "Epoch 92/100\n",
            "64/64 [==============================] - 0s 4ms/step - loss: 112.9080 - val_loss: 110.0766\n",
            "Epoch 93/100\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 111.8287 - val_loss: 109.2336\n",
            "Epoch 94/100\n",
            "64/64 [==============================] - 0s 4ms/step - loss: 110.8796 - val_loss: 108.4353\n",
            "Epoch 95/100\n",
            "64/64 [==============================] - 0s 4ms/step - loss: 110.0096 - val_loss: 107.7568\n",
            "Epoch 96/100\n",
            "64/64 [==============================] - 0s 4ms/step - loss: 109.2140 - val_loss: 107.1853\n",
            "Epoch 97/100\n",
            "64/64 [==============================] - 0s 5ms/step - loss: 108.4903 - val_loss: 106.6096\n",
            "Epoch 98/100\n",
            "64/64 [==============================] - 0s 4ms/step - loss: 107.8261 - val_loss: 106.1776\n",
            "Epoch 99/100\n",
            "64/64 [==============================] - 0s 4ms/step - loss: 107.2540 - val_loss: 105.8449\n",
            "Epoch 100/100\n",
            "64/64 [==============================] - 0s 5ms/step - loss: 106.7584 - val_loss: 105.5703\n",
            "CPU times: user 34.5 s, sys: 1.33 s, total: 35.8 s\n",
            "Wall time: 43.1 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "the model progresses with a final loss of roughly 105 on the final epoch. It's accuracy is shown below and is on par with the previous Linear Regresion model. "
      ],
      "metadata": {
        "id": "xSlyk1DnJB0t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = model.evaluate(test_copy, testing_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2LYhJdI4uXa",
        "outputId": "c996787f-60e0-4269-8a00-965fe851be0d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 0s 2ms/step - loss: 97.5620\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "le_0XsRb5ICv",
        "outputId": "e8013cf8-174b-4cac-a6bb-ee92f0200e5d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "97.56195068359375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_data = np.array([6,3.5,10.0,1])\n",
        "\n",
        "predictions = model.predict(new_data)\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3rp5nnn9F2U",
        "outputId": "8192c80f-431e-4f18-aadf-edae8f347379"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 165ms/step\n",
            "[[553.36896]\n",
            " [553.36896]\n",
            " [553.36896]\n",
            " [553.36896]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclutions**\n",
        "\n",
        "from this report it can be concluded that in certain simpler cases, a liear regrestion model can be more suitable for a situation then a DNN, as the LR model seemed to work better."
      ],
      "metadata": {
        "id": "kDYBnYjXKA2x"
      }
    }
  ]
}